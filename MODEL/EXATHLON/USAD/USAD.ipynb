{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gioel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\gioel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\Users\\gioel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.utils.data as data_utils\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils_USAD'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gioel\\OneDrive\\Desktop\\TESI_GIOELE_VERZE\\EXATHLON\\USAD\\USAD.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gioel/OneDrive/Desktop/TESI_GIOELE_VERZE/EXATHLON/USAD/USAD.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gioel/OneDrive/Desktop/TESI_GIOELE_VERZE/EXATHLON/USAD/USAD.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/gioel/OneDrive/Desktop/TESI_GIOELE_VERZE/EXATHLON/USAD/USAD.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils_USAD\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gioel/OneDrive/Desktop/TESI_GIOELE_VERZE/EXATHLON/USAD/USAD.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m device \u001b[39m=\u001b[39m get_default_device()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gioel/OneDrive/Desktop/TESI_GIOELE_VERZE/EXATHLON/USAD/USAD.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mEncoder\u001b[39;00m(nn\u001b[39m.\u001b[39mModule):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils_USAD'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from utils_USAD import *\n",
    "device = get_default_device()\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "  def __init__(self, in_size, latent_size):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.linear1 = nn.Linear(in_size, int(in_size/2))\n",
    "    self.linear2 = nn.Linear(int(in_size/2), int(in_size/4))\n",
    "    self.linear3 = nn.Linear(int(in_size/4), latent_size)\n",
    "    self.relu = nn.ReLU(True)\n",
    "        \n",
    "  def forward(self, w):\n",
    "    out = self.linear1(w)\n",
    "    out = self.relu(out)\n",
    "    out = self.linear2(out)\n",
    "    out = self.relu(out)\n",
    "    out = self.linear3(out)\n",
    "    z = self.relu(out)\n",
    "\n",
    "    return z\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "  def __init__(self, latent_size, out_size):\n",
    "    super().__init__()\n",
    "\n",
    "    self.linear1 = nn.Linear(latent_size, int(out_size/4))\n",
    "    self.linear2 = nn.Linear(int(out_size/4), int(out_size/2))\n",
    "    self.linear3 = nn.Linear(int(out_size/2), out_size)\n",
    "    self.relu = nn.ReLU(True)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        \n",
    "  def forward(self, z):\n",
    "\n",
    "    out = self.linear1(z)\n",
    "    out = self.relu(out)\n",
    "    out = self.linear2(out)\n",
    "    out = self.relu(out)\n",
    "    out = self.linear3(out)\n",
    "    w = self.sigmoid(out)\n",
    "    return w\n",
    "    \n",
    "class UsadModel(nn.Module):\n",
    "  def __init__(self, w_size, z_size):\n",
    "    super().__init__()\n",
    "    self.encoder = Encoder(w_size, z_size)\n",
    "    self.decoder1 = Decoder(z_size, w_size)\n",
    "    self.decoder2 = Decoder(z_size, w_size)\n",
    "  \n",
    "  def training_step(self, batch, n):\n",
    "    z = self.encoder(batch)\n",
    "    w1 = self.decoder1(z)\n",
    "    w2 = self.decoder2(z)\n",
    "    w3 = self.decoder2(self.encoder(w1))\n",
    "    loss1 = 1/n*torch.mean((batch-w1)**2)+(1-1/n)*torch.mean((batch-w3)**2)\n",
    "    loss2 = 1/n*torch.mean((batch-w2)**2)-(1-1/n)*torch.mean((batch-w3)**2)\n",
    "    return loss1,loss2\n",
    "\n",
    "  def validation_step(self, batch, n):\n",
    "    z = self.encoder(batch)\n",
    "    w1 = self.decoder1(z)\n",
    "    w2 = self.decoder2(z)\n",
    "    w3 = self.decoder2(self.encoder(w1))\n",
    "    loss1 = 1/n*torch.mean((batch-w1)**2)+(1-1/n)*torch.mean((batch-w3)**2)\n",
    "    loss2 = 1/n*torch.mean((batch-w2)**2)-(1-1/n)*torch.mean((batch-w3)**2)\n",
    "    return {'val_loss1': loss1, 'val_loss2': loss2}\n",
    "        \n",
    "  def validation_epoch_end(self, outputs):\n",
    "    batch_losses1 = [x['val_loss1'] for x in outputs]\n",
    "    epoch_loss1 = torch.stack(batch_losses1).mean()\n",
    "    batch_losses2 = [x['val_loss2'] for x in outputs]\n",
    "    epoch_loss2 = torch.stack(batch_losses2).mean()\n",
    "    return {'val_loss1': epoch_loss1.item(), 'val_loss2': epoch_loss2.item()}\n",
    "    \n",
    "  def epoch_end(self, epoch, result):\n",
    "    print(\"Epoch [{}], val_loss1: {:.4f}, val_loss2: {:.4f}\".format(epoch, result['val_loss1'], result['val_loss2']))\n",
    "    \n",
    "def evaluate(model, val_loader, n):\n",
    "    outputs = [model.validation_step(to_device(batch,device), n) for [batch] in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def training(epochs, model, train_loader, val_loader, opt_func=torch.optim.Adam):\n",
    "    history = []\n",
    "\n",
    "\n",
    "    optimizer1 = opt_func(list(model.encoder.parameters())+list(model.decoder1.parameters()))\n",
    "    optimizer2 = opt_func(list(model.encoder.parameters())+list(model.decoder2.parameters()))\n",
    "    for epoch in range(epochs):\n",
    "        for [batch] in train_loader:\n",
    "            batch=to_device(batch,device)\n",
    "            \n",
    "            #Train AE1\n",
    "            loss1,loss2 = model.training_step(batch,epoch+1)\n",
    "            loss1.backward()\n",
    "            optimizer1.step()\n",
    "            optimizer1.zero_grad()\n",
    "            \n",
    "            \n",
    "            #Train AE2\n",
    "            loss1,loss2 = model.training_step(batch,epoch+1)\n",
    "            loss2.backward()\n",
    "            optimizer2.step()\n",
    "            optimizer2.zero_grad()\n",
    "            \n",
    "            \n",
    "        result = evaluate(model, val_loader, epoch+1)\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history\n",
    "    \n",
    "def testing(model, test_loader, alpha=.5, beta=.5):\n",
    "    results=[]\n",
    "    for [batch] in test_loader:\n",
    "        batch=to_device(batch,device)\n",
    "        w1=model.decoder1(model.encoder(batch))\n",
    "        w2=model.decoder2(model.encoder(w1))\n",
    "        results.append(alpha*torch.mean((batch-w1)**2,axis=1)+beta*torch.mean((batch-w2)**2,axis=1))\n",
    "        #results.append(alpha*(batch-w1)**2+beta*(batch-w2)**2)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE=40\n",
    "def create_sequences(values, time_steps=WINDOW_SIZE):\n",
    "    output = []\n",
    "    for i in range(len(values) - time_steps + 1):\n",
    "        output.append(values[i : (i + time_steps)])\n",
    "    return np.stack(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UsadModel(\n",
      "  (encoder): Encoder(\n",
      "    (linear1): Linear(in_features=760, out_features=380, bias=True)\n",
      "    (linear2): Linear(in_features=380, out_features=190, bias=True)\n",
      "    (linear3): Linear(in_features=190, out_features=100, bias=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (decoder1): Decoder(\n",
      "    (linear1): Linear(in_features=100, out_features=190, bias=True)\n",
      "    (linear2): Linear(in_features=190, out_features=380, bias=True)\n",
      "    (linear3): Linear(in_features=380, out_features=760, bias=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      "  (decoder2): Decoder(\n",
      "    (linear1): Linear(in_features=100, out_features=190, bias=True)\n",
      "    (linear2): Linear(in_features=190, out_features=380, bias=True)\n",
      "    (linear3): Linear(in_features=380, out_features=760, bias=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Epoch [0], val_loss1: 0.8662, val_loss2: 0.8662\n",
      "Epoch [1], val_loss1: 0.8662, val_loss2: 0.0000\n",
      "Epoch [2], val_loss1: 0.8662, val_loss2: -0.2887\n",
      "Epoch [3], val_loss1: 0.8662, val_loss2: -0.4331\n",
      "Epoch [4], val_loss1: 0.8662, val_loss2: -0.5197\n",
      "Epoch [5], val_loss1: 0.8662, val_loss2: -0.5774\n",
      "Epoch [6], val_loss1: 0.8662, val_loss2: -0.6187\n",
      "Epoch [7], val_loss1: 0.8662, val_loss2: -0.6496\n",
      "Epoch [8], val_loss1: 0.8662, val_loss2: -0.6737\n",
      "Epoch [9], val_loss1: 0.8662, val_loss2: -0.6929\n",
      "Epoch [10], val_loss1: 0.8662, val_loss2: -0.7087\n",
      "Epoch [11], val_loss1: 0.8662, val_loss2: -0.7218\n",
      "Epoch [12], val_loss1: 0.8662, val_loss2: -0.7329\n",
      "Epoch [13], val_loss1: 0.8662, val_loss2: -0.7424\n",
      "Epoch [14], val_loss1: 0.8662, val_loss2: -0.7507\n",
      "Epoch [15], val_loss1: 0.8662, val_loss2: -0.7579\n",
      "Epoch [16], val_loss1: 0.8662, val_loss2: -0.7643\n",
      "Epoch [17], val_loss1: 0.8662, val_loss2: -0.7699\n",
      "Epoch [18], val_loss1: 0.8662, val_loss2: -0.7750\n",
      "Epoch [19], val_loss1: 0.8662, val_loss2: -0.7796\n",
      "Epoch [20], val_loss1: 0.8662, val_loss2: -0.7837\n",
      "Epoch [21], val_loss1: 0.8662, val_loss2: -0.7874\n",
      "Epoch [22], val_loss1: 0.8662, val_loss2: -0.7908\n",
      "Epoch [23], val_loss1: 0.8662, val_loss2: -0.7940\n",
      "Epoch [24], val_loss1: 0.8662, val_loss2: -0.7969\n",
      "Epoch [25], val_loss1: 0.8662, val_loss2: -0.7995\n",
      "Epoch [26], val_loss1: 0.8662, val_loss2: -0.8020\n",
      "Epoch [27], val_loss1: 0.8662, val_loss2: -0.8043\n",
      "Epoch [28], val_loss1: 0.8662, val_loss2: -0.8064\n",
      "Epoch [29], val_loss1: 0.8662, val_loss2: -0.8084\n",
      "Epoch [30], val_loss1: 0.8662, val_loss2: -0.8103\n",
      "Epoch [31], val_loss1: 0.8662, val_loss2: -0.8120\n",
      "Epoch [32], val_loss1: 0.8662, val_loss2: -0.8137\n",
      "Epoch [33], val_loss1: 0.8662, val_loss2: -0.8152\n",
      "Epoch [34], val_loss1: 0.8662, val_loss2: -0.8167\n",
      "Epoch [35], val_loss1: 0.8662, val_loss2: -0.8180\n",
      "Epoch [36], val_loss1: 0.8662, val_loss2: -0.8193\n",
      "Epoch [37], val_loss1: 0.8662, val_loss2: -0.8206\n",
      "Epoch [38], val_loss1: 0.8662, val_loss2: -0.8217\n",
      "Epoch [39], val_loss1: 0.8662, val_loss2: -0.8229\n",
      "Epoch [40], val_loss1: 0.8662, val_loss2: -0.8239\n",
      "Epoch [41], val_loss1: 0.8662, val_loss2: -0.8249\n",
      "Epoch [42], val_loss1: 0.8662, val_loss2: -0.8259\n",
      "Epoch [43], val_loss1: 0.8662, val_loss2: -0.8268\n",
      "Epoch [44], val_loss1: 0.8662, val_loss2: -0.8277\n",
      "Epoch [45], val_loss1: 0.8662, val_loss2: -0.8285\n",
      "Epoch [46], val_loss1: 0.8662, val_loss2: -0.8293\n",
      "Epoch [47], val_loss1: 0.8662, val_loss2: -0.8301\n",
      "Epoch [48], val_loss1: 0.8662, val_loss2: -0.8308\n",
      "Epoch [49], val_loss1: 0.8662, val_loss2: -0.8315\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "BATCH_SIZE =  64\n",
    "N_EPOCHS = 50\n",
    "hidden_size = 100\n",
    "\n",
    "\n",
    "with open(f'.././DATA_SPLITTED/app_tot.pkl', 'rb') as f:\n",
    "            DATA= pickle.load(f)\n",
    "\n",
    "\n",
    "X_train=DATA['X_train']\n",
    "X_val=DATA['X_val']\n",
    "X_test=DATA['X_test']\n",
    "\n",
    "w_size=X_train.shape[1]*X_train.shape[2]\n",
    "z_size=hidden_size\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(data_utils.TensorDataset(\n",
    "        torch.from_numpy(X_train).float().reshape(([X_train.shape[0],w_size]))\n",
    "    ) , batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(data_utils.TensorDataset(\n",
    "        torch.from_numpy(X_val).float().reshape(([X_val.shape[0],w_size]))\n",
    "    ) , batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(data_utils.TensorDataset(\n",
    "        torch.from_numpy(X_test).float().reshape(([X_test.shape[0],w_size]))\n",
    "    ) , batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "model = UsadModel(w_size, z_size)\n",
    "model = to_device(model,device)\n",
    "print(model)\n",
    "history = training(N_EPOCHS,model,train_loader,val_loader)\n",
    "#history = training(N_EPOCHS,model,train_loader,train_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(data_utils.TensorDataset(\n",
    "        torch.from_numpy(X_test).float().reshape(([X_test.shape[0],w_size]))\n",
    "    ) , batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "results=testing(model,test_loader)\n",
    "\n",
    "y_pred=np.concatenate([torch.stack(results[:-1]).flatten().detach().cpu().numpy(),\n",
    "                                results[-1].flatten().detach().cpu().numpy()])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=DATA['X_test'][:,:,:].mean(axis=(1,2))\n",
    "score=np.power(y_pred-data,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'USAD.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gioel\\OneDrive\\Desktop\\exathlon\\USAD.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gioel/OneDrive/Desktop/exathlon/USAD.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcsv\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gioel/OneDrive/Desktop/exathlon/USAD.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m header\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mth_factor\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mmethod\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mF1\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mprecision\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mrecall\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mTP\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mTN\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mFP\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mFN\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/gioel/OneDrive/Desktop/exathlon/USAD.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mUSAD.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mUTF8\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gioel/OneDrive/Desktop/exathlon/USAD.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     writer \u001b[39m=\u001b[39m csv\u001b[39m.\u001b[39mwriter(f)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gioel/OneDrive/Desktop/exathlon/USAD.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     writer\u001b[39m.\u001b[39mwriterow(header)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'USAD.csv'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "header=['th_factor','method','value','F1','precision','recall','TP','TN','FP','FN']\n",
    "\n",
    "with open('USAD.csv', 'w', encoding='UTF8') as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    writer.writerow(header)\n",
    "    thresholding_factor=[0.5,1,1.5,2]\n",
    "    for t in thresholding_factor:\n",
    "        #IQR\n",
    "        q1, q3 = np.percentile(score, 25), np.percentile(score, 75)\n",
    "        iqr = q3 - q1\n",
    "        IQR = q3 + t* iqr\n",
    "\n",
    "        #MAD\n",
    "        median = np.median(score)\n",
    "        mad = 1.4826 * np.median(np.abs(score - median))\n",
    "        MAD = median + t * mad\n",
    "\n",
    "        #STD\n",
    "        mean, std = np.mean(score), np.std(score)\n",
    "        STD = mean + t * std\n",
    "\n",
    "        method=[IQR,MAD,STD]\n",
    "        for g in range(len(method)):\n",
    "            TP=0\n",
    "            TN=0\n",
    "            FN=0\n",
    "            FP=0\n",
    "\n",
    "            for i in tqdm(range(1,11)):\n",
    "                if(i!=7):\n",
    "                \n",
    "                    TEST=np.load(f'.././OUTPUTS_ROOT/data/processed/spark_0_15s/spark_0_trace-scl_std/test{i}.npy',allow_pickle=True)\n",
    "\n",
    "                    ANOMALY=np.load(f'.././OUTPUTS_ROOT/data/processed/spark_0_15s/spark_0_trace-scl_std/y_test{i}.npy',allow_pickle=True)\n",
    "\n",
    "                    with open(f'.././OUTPUTS_ROOT/data/interim/spark_0_15s/test_info{i}.pkl', 'rb') as f:\n",
    "                        TEST_info= pickle.load(f)\n",
    "\n",
    "                    for x in range(len(TEST_info)):\n",
    "\n",
    "                        X=create_sequences(TEST[x])\n",
    "\n",
    "                        test_loader = torch.utils.data.DataLoader(data_utils.TensorDataset(\n",
    "                                torch.from_numpy(X).float().reshape(([X.shape[0],w_size]))\n",
    "                            ) , batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "                        \n",
    "                        results=testing(model,test_loader)\n",
    "\n",
    "                        Y=np.concatenate([torch.stack(results[:-1]).flatten().detach().cpu().numpy(),\n",
    "                                            results[-1].flatten().detach().cpu().numpy()])\n",
    "                        \n",
    "                        error=np.power(X[:,:,:].mean(axis=(1,2))-Y,2)\n",
    "                        error=[error[l] if error[l]<3 else 2 for l in range(len(error))]\n",
    "\n",
    "                        outlier=error>method[g]\n",
    "\n",
    "                        le=len(outlier)\n",
    "\n",
    "                        true_= ANOMALY[x][20:20+le]>=1\n",
    "                        prediction_ = outlier[:].astype(int)==1\n",
    "                        #plt.plot(true_.astype(int)/100)\n",
    "                        TP = TP+(true_ & prediction_).sum()   \n",
    "                        TN = TN+(~true_ & ~prediction_).sum()  \n",
    "                        FP = FP+(~true_ & prediction_).sum()    \n",
    "                        FN = FN+(true_ & ~prediction_).sum()    \n",
    "\n",
    "            PREC=TP / (TP + FP)\n",
    "            REC = TP/ (TP+FN)\n",
    "            f1=2 * PREC * REC/(PREC + REC)\n",
    "            m=['IQR','MAD','STD']\n",
    "            row=[t,m[g],method[g],f1,PREC,REC,TP,TN,FP,FN]\n",
    "            writer.writerow(row)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7732ff24e494917fdc04ba71f0b346f07dc6128216c19827ae3641c937bc9395"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
